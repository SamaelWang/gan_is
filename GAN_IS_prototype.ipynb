{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from math import exp, log\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from cvxopt import matrix\n",
    "from cvxopt.blas import dot\n",
    "from cvxopt import solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_samples(dist_type):\n",
    "    if dist_type == 'normal':\n",
    "        def gen_norm_samples(nums, mu, sigma):\n",
    "            return np.random.randn(nums) * sigma + mu\n",
    "        return gen_norm_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_norm_samples = gen_samples('normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_func = partial(gen_norm_samples, mu=0.0, sigma=1.0)\n",
    "X = sample_func(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gammak(arr_g, rho):\n",
    "    num = len(arr_g)\n",
    "    index = int(np.ceil((1-rho)*num))\n",
    "    arr_g.sort()\n",
    "    return arr_g[index - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_0 = compute_gammak(X, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_conditional_samples(num, gamma, sample_func):\n",
    "    res = np.empty((0))\n",
    "    rest_num = num\n",
    "    while rest_num > 0:\n",
    "        cur_samples = sample_func(num * 10)\n",
    "        res = np.concatenate((res, cur_samples[cur_samples > gamma]), axis=None)\n",
    "        rest_num = num - len(res)\n",
    "    return res[:num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = gen_conditional_samples(100, gamma_0, sample_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# p_data\n",
    "xs = gen_conditional_samples(10000, gamma_0, sample_func)\n",
    "n, bins, patches = plt.hist(xs, 50, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one of the problem of GAN, easily to be more concentrated at \"high mode\"\n",
    "# techniques such as minibatch discrimination might help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.261842416188064"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: importance sampling GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently we focus on one dimension normal random variable, g(X) = X\n",
    "# barrier func should be e^{-(x-y)^2}/2h-c/2(log(x-gamma)-log(y-gamma))^2\n",
    "def compute_sp(dist_type):\n",
    "    if dist_type == 'normal':\n",
    "        def normal_sp(x, mu, sigma):\n",
    "            return -(x-mu)/(sigma**2)\n",
    "        return normal_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel_info(kernel_type):\n",
    "    if kernel_type == 'normal_barrier':\n",
    "        def normal_barrier(x, y, h, c, gamma):   #TODO: g(x) might be needed in the future, SymPy might be useful to compute symbolic derivative\n",
    "            kernel_info = {}\n",
    "            kernel_info['kernel'] = np.exp(-(x-y)*(x-y)/(2.0*h)-(c*(np.log(x-gamma)-np.log(y-gamma))*(np.log(x-gamma)-np.log(y-gamma)))/2.0)\n",
    "            kernel_info['grad_x'] = kernel_info['kernel'] * (-(x-y)/h-c*(np.log(x-gamma)-np.log(y-gamma))/(x-gamma))\n",
    "            kernel_info['grad_y'] = kernel_info['kernel'] * ((x-y)/h+c*(np.log(x-gamma)-np.log(y-gamma))/(y-gamma))\n",
    "            kernel_info['hessian'] = kernel_info['grad_y']*(-(x-y)/h-c*(np.log(x-gamma)-np.log(y-gamma))/(x-gamma)) +\\\n",
    "            kernel_info['kernel']*(1.0/h+c/((x-gamma)*(y-gamma)))\n",
    "            return kernel_info\n",
    "        return normal_barrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute kernel p\n",
    "def compute_kernel_p(x, y, sp, kernel_info):\n",
    "    kernel_vals = kernel_info(x,y)\n",
    "    kernel = kernel_vals['kernel']\n",
    "    grad_x = kernel_vals['grad_x']\n",
    "    grad_y = kernel_vals['grad_y']\n",
    "    hessian_kernel = kernel_vals['hessian']\n",
    "    return sp(x)*kernel*sp(y) + sp(x)*grad_y + sp(y)*grad_x + hessian_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute blackbox importance weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Kp(samples, sp_input, ki_input):\n",
    "    n = len(samples)\n",
    "    Kp = np.zeros((n,n))\n",
    "    p_kernel = partial(compute_kernel_p, sp=sp_input, kernel_info=ki_input)\n",
    "    idx = np.array([[i, j] for i in range(n) for j in range(i, n)])\n",
    "    s1 = samples[idx[:,0]]\n",
    "    s2 = samples[idx[:,1]]\n",
    "    res = p_kernel(s1, s2)\n",
    "    Kp[np.triu_indices(n)] = res\n",
    "    Kp = matrix(Kp.T+Kp-np.diag(np.diag(Kp)))\n",
    "    return Kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_is_weights(Kp):\n",
    "    n = Kp.size[0]\n",
    "    p = matrix(0.0, (n,1))\n",
    "    G = matrix(0.0, (n,n))\n",
    "    G[::n+1] = -1.0\n",
    "    h = matrix(0.0, (n,1))\n",
    "    A = matrix(1.0, (1,n))\n",
    "    b = matrix(1.0)\n",
    "    res = solvers.qp(Kp, p, G, h, A, b)\n",
    "    wi = np.array(res['x'])\n",
    "    return wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISGAN(object):\n",
    "    \n",
    "    def __init__(self, gan_id, sess, total_epoch, batch_size, n_input, n_noise, n_hidden, early_stopping_rounds, learning_rate, gamma_0, is_enabled):\n",
    "        self.gan_id = gan_id\n",
    "        self.sess = sess\n",
    "        self.total_epoch = total_epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.n_input = n_input\n",
    "        self.n_noise = n_noise\n",
    "        self.n_hidden = n_hidden\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma_0 = gamma_0\n",
    "        self.is_enabled = is_enabled\n",
    "        if self.is_enabled:\n",
    "            normal_sp = compute_sp('normal')\n",
    "            self.std_normal_sp = partial(normal_sp, mu=0.0, sigma=1.0)\n",
    "            normal_barrier = compute_kernel_info('normal_barrier')\n",
    "            self.normal_barrier_param = partial(normal_barrier, h=1.0, c=1.0, gamma=self.gamma_0)\n",
    "        \n",
    "    def generator(self, noise_z):\n",
    "        with tf.variable_scope('generator' + self.gan_id) :\n",
    "            hidden_1 = tf.layers.dense(inputs=noise_z, units=self.n_hidden, activation=tf.nn.relu)\n",
    "            hidden_2 = tf.layers.dense(inputs=hidden_1, units=self.n_hidden, activation=tf.nn.relu)\n",
    "            output = tf.layers.dense(inputs=hidden_2, units=self.n_input, activation=tf.nn.softplus)\n",
    "        return output\n",
    "\n",
    "    def discriminator(self, inputs, reuse=None):\n",
    "        with tf.variable_scope('discriminator' + self.gan_id) as scope:\n",
    "            # In order to make the variables of the models that discriminate the actual image from the images generated by the noise the same,\n",
    "            # Reuse the previously used variables.\n",
    "\n",
    "            if reuse :\n",
    "                scope.reuse_variables()\n",
    "\n",
    "            hidden = tf.layers.dense(inputs=inputs, units=self.n_hidden, activation=tf.nn.relu)\n",
    "            output = tf.layers.dense(inputs=hidden, units=self.n_input, activation=tf.nn.sigmoid)\n",
    "        return output\n",
    "\n",
    "    def get_noise(self, batch_size, n_noise) :\n",
    "        #return (np.random.random(size=(batch_size, n_noise))-0.5)*2.0\n",
    "        return np.random.normal(size=(batch_size, n_noise))\n",
    "    \n",
    "    def build_model(self):\n",
    "        # input X\n",
    "        self.X = tf.placeholder(tf.float32, [None, self.n_input])\n",
    "        # Use noise Z as input value.\n",
    "        self.Z = tf.placeholder(tf.float32, [None, self.n_noise])\n",
    "        # Importance weights W\n",
    "        self.W = tf.placeholder(tf.float32, [None, self.n_input])\n",
    "        self.G = self.generator(self.Z)\n",
    "        # Returns the value determined using the real image.\n",
    "        self.D_real = tf.maximum(tf.minimum(self.discriminator(self.X), 0.99), 0.01)\n",
    "        # Returns a value that determines whether the image created using noise is a real image.\n",
    "        self.D_gene = tf.maximum(tf.minimum(self.discriminator(self.G, reuse=True), 0.99), 0.01)\n",
    "        self.loss_D = tf.reduce_mean(tf.multiply(tf.log(self.D_real), self.W) + tf.log(1 - self.D_gene))\n",
    "        #tf.summary.scalar('loss_D', -self.loss_D)\n",
    "        self.loss_G = tf.reduce_mean(tf.log(self.D_gene))\n",
    "        #tf.summary.scalar('loss_G', -self.loss_G)\n",
    "        # When loss_D is obtained, only variables used in the generator neural network are used,\n",
    "        vars_D = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator' + self.gan_id)\n",
    "        vars_G = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator' + self.gan_id)\n",
    "        # According to the GAN thesis formula, the loss should be maximized, but since the optimization function is used to minimize it, a negative sign is added to loss_D and loss_G to be optimized.\n",
    "        self.train_D = tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate).minimize(-self.loss_D, var_list=vars_D)\n",
    "        #train_D = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(-loss_D, var_list=vars_D)\n",
    "        self.train_G = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(-self.loss_G, var_list=vars_G)\n",
    "        \n",
    "    \n",
    "    def train(self, sampling_func):\n",
    "        self.histd, self.histg = [], []\n",
    "        # Start training !\n",
    "        k = 4\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        loss_val_D, loss_val_G = 0.0, 0.0\n",
    "        prev_avg_D_cost = 0.0\n",
    "        prev_avg_G_cost = 0.0\n",
    "        for epoch in range(self.total_epoch):\n",
    "            avg_D_cost = 0.0\n",
    "            avg_G_cost = 0.0\n",
    "            for i in range(self.early_stopping_rounds):\n",
    "                for j in range(k):\n",
    "                    batch_x = gen_conditional_samples(self.batch_size, self.gamma_0, sampling_func)\n",
    "                    batch_x.sort() # it's better to sort the data first\n",
    "                    if self.is_enabled == True:\n",
    "                        Kp = compute_Kp(batch_x, self.std_normal_sp, self.normal_barrier_param)\n",
    "                        is_weights = np.reshape(compute_is_weights(Kp)*self.batch_size, (self.batch_size, 1))\n",
    "                    else:\n",
    "                        is_weights = np.ones((self.batch_size, 1))\n",
    "                    noise = self.get_noise(self.batch_size, self.n_noise)\n",
    "                    noise.sort(axis=0)\n",
    "                    # It learns discriminator and generator neural network separately.\n",
    "                    _, loss_val_D = self.sess.run([self.train_D, self.loss_D],\n",
    "                                                 feed_dict={self.X : np.reshape(batch_x, (self.batch_size, 1)), self.Z : noise, self.W: is_weights})\n",
    "                    # replace np.ones with other weights\n",
    "                self.histd.append(loss_val_D)\n",
    "                noise = self.get_noise(self.batch_size, self.n_noise)\n",
    "                noise.sort(axis=0)\n",
    "                _, loss_val_G = self.sess.run([self.train_G, self.loss_G],\n",
    "                                             feed_dict={self.Z : noise})\n",
    "                self.histg.append(loss_val_G)\n",
    "                avg_D_cost += loss_val_D / self.early_stopping_rounds\n",
    "                avg_G_cost += loss_val_G / self.early_stopping_rounds\n",
    "                #if (epoch*self.early_stopping_rounds+i) % (self.total_epoch * self.early_stopping_rounds//10) == 0:\n",
    "                #    print(float(epoch*self.early_stopping_rounds+i)/float(self.total_epoch * self.early_stopping_rounds))\n",
    "            # early stopping logic\n",
    "            if np.abs(prev_avg_D_cost - avg_D_cost) < 0.0001 and np.abs(prev_avg_G_cost - avg_G_cost) < 0.0001:\n",
    "                print(\"Stopping early, epoch = \", epoch)\n",
    "                break\n",
    "            prev_avg_D_cost = avg_D_cost\n",
    "            prev_avg_G_cost = avg_G_cost\n",
    "            if epoch % 10 == 0:\n",
    "                print(epoch)\n",
    "            #summary = sess.run(merged, feed_dict={X: np.reshape(batch_x, (batch_size, 1)), Z: noise})\n",
    "            #writer.add_summary(summary, global_step=epoch)\n",
    "                \n",
    "    \n",
    "    def gan_sampler(self, n):\n",
    "        if n < self.batch_size:\n",
    "            z = self.get_noise(self.batch_size, self.n_noise)\n",
    "            gs = self.sess.run(self.G, {self.Z:z})\n",
    "            return gs[:n][:,0]\n",
    "        else:\n",
    "            gs = np.zeros((n,self.n_input))\n",
    "            div = n // self.batch_size\n",
    "            rem = n % self.batch_size\n",
    "            for i in range(div):\n",
    "                z = self.get_noise(self.batch_size, 1)\n",
    "                gs[self.batch_size*i:self.batch_size*(i+1)] = self.sess.run(self.G, {self.Z:z})\n",
    "            z = self.get_noise(rem, self.n_noise)\n",
    "            gs[div*self.batch_size:] = self.sess.run(self.G, {self.Z:z})\n",
    "            return gs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "2390\n",
      "2400\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "2440\n",
      "2450\n",
      "2460\n",
      "2470\n",
      "2480\n",
      "2490\n",
      "2500\n",
      "2510\n",
      "2520\n",
      "2530\n",
      "2540\n",
      "2550\n",
      "2560\n",
      "2570\n",
      "2580\n",
      "2590\n",
      "2600\n",
      "2610\n",
      "2620\n",
      "2630\n",
      "2640\n",
      "2650\n",
      "2660\n",
      "2670\n",
      "2680\n",
      "2690\n",
      "2700\n",
      "2710\n",
      "2720\n",
      "2730\n",
      "2740\n",
      "2750\n",
      "2760\n",
      "2770\n",
      "2780\n",
      "2790\n",
      "2800\n",
      "2810\n",
      "2820\n",
      "2830\n",
      "2840\n",
      "2850\n",
      "2860\n",
      "2870\n",
      "2880\n",
      "2890\n",
      "2900\n",
      "2910\n",
      "2920\n",
      "2930\n",
      "2940\n",
      "2950\n",
      "2960\n",
      "2970\n",
      "2980\n",
      "2990\n",
      "3000\n",
      "3010\n",
      "3020\n",
      "3030\n",
      "3040\n",
      "3050\n",
      "3060\n",
      "3070\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4fea152b9607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mISGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# input is weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgan_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-19002540d89c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sampling_func)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                     \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_conditional_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                     \u001b[0mbatch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# it's better to sort the data first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_enabled\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-30665525634e>\u001b[0m in \u001b[0;36mgen_conditional_samples\u001b[0;34m(num, gamma, sample_func)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrest_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mrest_num\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mcur_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mrest_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-061f66521353>\u001b[0m in \u001b[0;36mgen_norm_samples\u001b[0;34m(nums, mu, sigma)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdist_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'normal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mgen_norm_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgen_norm_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    gan = ISGAN('-1', sess, 5000, 200, 1, 1, 6, 50, 0.0003, gamma_0, False)\n",
    "    gan.build_model()\n",
    "    gan.train(sample_func) # input is weights\n",
    "    gs = gan.gan_sampler(100000)\n",
    "    n, bins, patches = plt.hist(gs, 50, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(gan.histd)), gan.histd, label='obj_d')\n",
    "plt.plot(range(len(gan.histg)), gan.histg, label='obj_g')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "Stopping early, epoch =  87\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "Stopping early, epoch =  92\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "Stopping early, epoch =  92\n"
     ]
    }
   ],
   "source": [
    "gamma = 5\n",
    "X = sample_func(5000)\n",
    "gamma_0 = compute_gammak(X, 0.15)\n",
    "#X_0 = gen_conditional_samples(1000, gamma_0, sample_func)\n",
    "sess_list = []\n",
    "sess0 = tf.Session()\n",
    "sess_list.append(sess0)\n",
    "gan = ISGAN('0', sess0, 5000, 200, 1, 1, 6, 50, 0.0003, gamma_0, False)\n",
    "gan.build_model()\n",
    "gan.train(sample_func)\n",
    "X_theta0 = gan.gan_sampler(5000)\n",
    "cur_gamma = compute_gammak(X_theta0, 0.15)\n",
    "idx = 1\n",
    "prev_gan = gan\n",
    "while cur_gamma < gamma:\n",
    "#X_theta1 = gen_conditional_samples(1000, cur_gamma, gan.gan_sampler)\n",
    "#conditional_gan_sampler = partial(gen_conditional_samples, gamma=cur_gamma, sample_func=gan.gan_sampler)\n",
    "    cur_sess = tf.Session()\n",
    "    sess_list.append(cur_sess)\n",
    "    cur_gan = ISGAN(str(idx), cur_sess, 5000, 200, 1, 1, 6, 50, 0.0003, cur_gamma, True)\n",
    "    cur_gan.build_model()\n",
    "    cur_gan.train(prev_gan.gan_sampler)\n",
    "    cur_gamma = compute_gammak(cur_gan.gan_sampler(5000), 0.15)\n",
    "    prev_gan = cur_gan\n",
    "    idx += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0569317297208518"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sample_func(5000)\n",
    "gamma_0 = compute_gammak(X, 0.15)\n",
    "gamma_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# samples of P_{theta_m+1} approximation of P(|g(X) > gamma)\n",
    "xs = cur_gan.gan_sampler(10000)\n",
    "n, bins, patches = plt.hist(xs, 50, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_kernel(x, y, h):   #TODO: g(x) might be needed in the future, SymPy might be useful to compute symbolic derivative\n",
    "    kernel_info = {}\n",
    "    kernel_info['kernel'] = np.exp(-(x-y)*(x-y)/(2.0*h))\n",
    "    kernel_info['grad_x'] = kernel_info['kernel'] * (-(x-y)/h)\n",
    "    kernel_info['grad_y'] = kernel_info['kernel'] * ((x-y)/h)\n",
    "    kernel_info['hessian'] = kernel_info['grad_y']*(-(x-y)/h)+kernel_info['kernel']*(1.0/h)\n",
    "    return kernel_info\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_sp = compute_sp('normal')\n",
    "std_normal_sp = partial(normal_sp, mu=0.0, sigma=1.0)\n",
    "normal_kernel_param = partial(normal_kernel, h=1.0)\n",
    "n = 1000\n",
    "xs = cur_gan.gan_sampler(n)\n",
    "Kp = compute_Kp(xs, std_normal_sp, normal_kernel_param)\n",
    "is_weights = np.reshape(compute_is_weights(Kp), (n, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.15132312e-09],\n",
       "       [1.28535750e-07],\n",
       "       [7.38176597e-09],\n",
       "       [3.68224806e-09],\n",
       "       [2.12650774e-09],\n",
       "       [9.19786208e-08],\n",
       "       [1.71968941e-09],\n",
       "       [1.95872562e-09],\n",
       "       [2.31662870e-09],\n",
       "       [3.81987363e-08]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_weights[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45049879])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final\n",
    "y = (xs > 5).astype(int)\n",
    "np.dot(y, is_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.866515719235352e-07"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "1 - norm.cdf(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_sp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c7b7d5ac4458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnormal_sp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_sp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstd_normal_sp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_sp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnormal_barrier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_kernel_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'normal_barrier'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnormal_barrier_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_barrier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_sp' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "normal_sp = compute_sp('normal')\n",
    "std_normal_sp = partial(normal_sp, mu=0.0, sigma=1.0)\n",
    "normal_barrier = compute_kernel_info('normal_barrier')\n",
    "normal_barrier_param = partial(normal_barrier, h=1.0, c=1.0, gamma=gamma_0)\n",
    "batch_x = gen_conditional_samples(200, gamma_0, gan.gan_sampler)\n",
    "start = time.time()\n",
    "Kp = compute_Kp(batch_x, std_normal_sp, normal_barrier_param)\n",
    "is_weights = np.reshape(compute_is_weights(Kp), (200, 1))\n",
    "end = time.time()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
